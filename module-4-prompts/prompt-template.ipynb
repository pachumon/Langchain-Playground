{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c29019ed",
   "metadata": {},
   "source": [
    "## Prompt Template Samples ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d776b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0454c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(subject):\n",
    "    prompt = f\"describe this topic: {subject}\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    reply = openai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return reply.choices[0].message.content\n",
    "\n",
    "question = input(\"please enter a prompt: \")\n",
    "reply = describe(question)\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d9104",
   "metadata": {},
   "source": [
    "## demo using PromptTemplate not dynamic ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42fd2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate(\n",
    "    input_variables=[],\n",
    "    template=\"what is chemistry?\"\n",
    ")\n",
    "template.format()  # \"what is chemistry?\"\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "print(llm.invoke(template.format()))  # The output will be a description of chemistry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664bebb8",
   "metadata": {},
   "source": [
    "## demo using PromptTemplate dynamic 1 param ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee13dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_template(subject):\n",
    "    template = PromptTemplate(\n",
    "        input_variables=[\"subject\"],\n",
    "        template=\"describe this topic: {subject}\"\n",
    "    )\n",
    "    prompt = template.format(subject=subject)\n",
    "    return llm.invoke(prompt)\n",
    "\n",
    "question = input(\"please enter a prompt: \")\n",
    "reply = describe_template(question)\n",
    "print(reply)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a6c181",
   "metadata": {},
   "source": [
    "## demo using PromptTemplate dynamic multi param ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330ac9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_template_two(subject, tone):\n",
    "    template = PromptTemplate(\n",
    "        input_variables=[\"subject\", \"tone\"],\n",
    "        template=\"describe this topic: {subject} in a {tone} tone\"\n",
    "    )\n",
    "    prompt = template.format(subject=subject, tone=tone)\n",
    "    return llm.invoke(prompt)\n",
    "\n",
    "question = input(\"please enter a prompt: \")\n",
    "tone = input(\"please enter a tone (e.g., professional, humorous, casual): \")\n",
    "reply = describe_template_two(question, tone)\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a6152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "def consult(expertise, question):\n",
    "    system_template = \"You are a helpful assistant that is an expert in {expertise}.\"\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "    human_template = \"{question}\"\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "    prompt = chat_prompt.format_prompt(expertise=expertise, question=question)\n",
    "    print(prompt.to_messages())\n",
    "    return llm.invoke(prompt.to_messages())\n",
    "\n",
    "expertise = input(\"Enter the area of expertise (e.g., history, science, technology): \")\n",
    "question = input(\"Enter your question: \")\n",
    "response = consult(expertise, question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8c8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"You are a helpful assistant that is an expert in {expertise}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "system_message_prompt.input_variables  # ['expertise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f2c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shakespeare_expert(modern_text_input):\n",
    "    template = \"you are a Shakespearean expert. Translate the following modern English text into Shakespearean English\"\n",
    "    system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "    modern_text = \"i updated my profile picture\"\n",
    "    modern_text_one = HumanMessagePromptTemplate.from_template(f\"{modern_text}\")\n",
    "\n",
    "    shakespere_text = \"i hath but refreshed mine own visage upon yon profile\"\n",
    "    shakespere_text_one = AIMessagePromptTemplate.from_template(f\"{shakespere_text}\")\n",
    "\n",
    "    modern_text = \"i bingewatched that series last night\"\n",
    "    modern_text_two = HumanMessagePromptTemplate.from_template(f\"{modern_text}\")\n",
    "\n",
    "    shakespere_text = \"verily, i did indulge in a marathon viewing of that series yesternight\"\n",
    "    shakespere_text_two = AIMessagePromptTemplate.from_template(f\"{shakespere_text}\")\n",
    "\n",
    "    human_template = \"{modern_text_input}\"\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        system_message_prompt,\n",
    "        modern_text_one,\n",
    "        shakespere_text_one,\n",
    "        modern_text_two,\n",
    "        shakespere_text_two,\n",
    "        human_message_prompt\n",
    "    ])\n",
    "    prompt = chat_prompt.format_prompt(modern_text_input=modern_text_input)\n",
    "    print(prompt.to_messages())\n",
    "    return llm.invoke(prompt.to_messages())\n",
    "\n",
    "modern_text_input = input(\"Enter the modern English text you want to translate to Shakespearean English: \")\n",
    "response = shakespeare_expert(modern_text_input = modern_text_input)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
